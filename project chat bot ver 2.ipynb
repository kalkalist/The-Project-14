{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The project:\n",
    "Train classifier: product query vs. everything else (a product request can be considered equal to the name or description of the product).\n",
    "\n",
    "Add logic to search for similar products by product query.\n",
    "\n",
    "All logic should be wrapped in a method **get_answer()**. The response to a product request should look like **\"product_id title\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\1\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "     -------------------------------------- 983.8/983.8 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.2.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.6/58.6 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.32\n",
      "    Uninstalling Cython-0.29.32:\n",
      "      Successfully uninstalled Cython-0.29.32\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: stop_words\n",
      "  Building wheel for stop_words (setup.py): started\n",
      "  Building wheel for stop_words (setup.py): finished with status 'done'\n",
      "  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32893 sha256=7778eb4403ef62b7fb95af70a58131b495696eacd99a886cca6f36db148e95ca\n",
      "  Stored in directory: c:\\users\\1\\appdata\\local\\pip\\cache\\wheels\\eb\\03\\0d\\3bd31c983789aeb0b4d5e2ca48590288d9db1586cf5f225062\n",
      "Successfully built stop_words\n",
      "Installing collected packages: stop_words\n",
      "Successfully installed stop_words-2018.7.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\1\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\1\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import annoy\n",
    "import pickle\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def preprocess_txt(line):\n",
    "    # Let's clean the line from punctuation. To do this, let's go over each character and check if it is a punctuation mark.\n",
    "    exclude = set(string.punctuation)\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    morpher = pymorphy2.MorphAnalyzer()\n",
    "    sw = set(stopwords.words(\"russian\"))\n",
    "    # Let's lemmatize all the words in our text\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls\n",
    "\n",
    "def prepro_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train the classifier “product request vs. chatter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and preprocess the dataset for training the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('ProductsDataset.csv')\n",
    "dataset.drop(['Unnamed: 0'], inplace = True, axis = 1)\n",
    "dataset['descrirption'] = dataset['descrirption'].apply(lambda x: x[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35548 entries, 0 to 35547\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           35548 non-null  object \n",
      " 1   descrirption    33537 non-null  object \n",
      " 2   product_id      35536 non-null  object \n",
      " 3   category_id     35536 non-null  float64\n",
      " 4   subcategory_id  35536 non-null  object \n",
      " 5   properties      35536 non-null  object \n",
      " 6   image_links     35533 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35543</th>\n",
       "      <td>Юбка</td>\n",
       "      <td>Юбка Белая по.Турция фирма adL</td>\n",
       "      <td>5b5f181c62e1c6616a7f6472</td>\n",
       "      <td>9.0</td>\n",
       "      <td>904</td>\n",
       "      <td>{'zhenskaya_odezhda_platya_yubki_tip': 'Юбки',...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35544</th>\n",
       "      <td>Новый твидовый пиджак</td>\n",
       "      <td>Новый с бирками пиджак размер S в стиле Coco C...</td>\n",
       "      <td>5bd6c8b29e94ba033d31f8d0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>908</td>\n",
       "      <td>{'brand_zhenskii': 'Chanel', 'zhenskaya_odezhd...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35545</th>\n",
       "      <td>Женская зимняя куртка</td>\n",
       "      <td>Женская зимняя спортивная куртка фирмы Rossiqn...</td>\n",
       "      <td>5bd6c8bc074b3e1c056f69b2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>903</td>\n",
       "      <td>{'zhenskaya_odezhda_razmer': '48-50 (XL)', 'zh...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35546</th>\n",
       "      <td>Новая золотая ветровка</td>\n",
       "      <td>Женская ветровка размер 44-46. Цвет приглушённ...</td>\n",
       "      <td>5bd6c8fb2138bbc55745362c</td>\n",
       "      <td>9.0</td>\n",
       "      <td>903</td>\n",
       "      <td>{'zhenskaya_odezhda_razmer': '44-46 (М)', 'zhe...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35547</th>\n",
       "      <td>Шарф</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5bd6c8fbaaab283b79142a1f</td>\n",
       "      <td>9.0</td>\n",
       "      <td>914</td>\n",
       "      <td>{'zhenskaya_odezhda_aksessuary_tip': 'Шарфы и ...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35548 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  \\\n",
       "0           Юбка детская ORBY   \n",
       "1                   Ботильоны   \n",
       "2                       Брюки   \n",
       "3        Продам детские шапки   \n",
       "4                      Блузка   \n",
       "...                       ...   \n",
       "35543                    Юбка   \n",
       "35544   Новый твидовый пиджак   \n",
       "35545   Женская зимняя куртка   \n",
       "35546  Новая золотая ветровка   \n",
       "35547                    Шарф   \n",
       "\n",
       "                                            descrirption  \\\n",
       "0      Новая, не носили ни разу. В реале красивей чем...   \n",
       "1      Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2      Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "3      Продам шапки,кажда 200р.Розовая и белая проданны.   \n",
       "4      Темно-синяя, 42 размер,состояние отличное,как ...   \n",
       "...                                                  ...   \n",
       "35543                     Юбка Белая по.Турция фирма adL   \n",
       "35544  Новый с бирками пиджак размер S в стиле Coco C...   \n",
       "35545  Женская зимняя спортивная куртка фирмы Rossiqn...   \n",
       "35546  Женская ветровка размер 44-46. Цвет приглушённ...   \n",
       "35547                                                NaN   \n",
       "\n",
       "                     product_id  category_id subcategory_id  \\\n",
       "0      58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1      5667531b2b7f8d127d838c34          9.0            902   \n",
       "2      59534826aaab284cba337e06          9.0            906   \n",
       "3      57de544096ad842e26de8027         22.0           2217   \n",
       "4      5ad4d2626c86cb168d212022          9.0            907   \n",
       "...                         ...          ...            ...   \n",
       "35543  5b5f181c62e1c6616a7f6472          9.0            904   \n",
       "35544  5bd6c8b29e94ba033d31f8d0          9.0            908   \n",
       "35545  5bd6c8bc074b3e1c056f69b2          9.0            903   \n",
       "35546  5bd6c8fb2138bbc55745362c          9.0            903   \n",
       "35547  5bd6c8fbaaab283b79142a1f          9.0            914   \n",
       "\n",
       "                                              properties  \\\n",
       "0            {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1      {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2      {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3      {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4      {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "...                                                  ...   \n",
       "35543  {'zhenskaya_odezhda_platya_yubki_tip': 'Юбки',...   \n",
       "35544  {'brand_zhenskii': 'Chanel', 'zhenskaya_odezhd...   \n",
       "35545  {'zhenskaya_odezhda_razmer': '48-50 (XL)', 'zh...   \n",
       "35546  {'zhenskaya_odezhda_razmer': '44-46 (М)', 'zhe...   \n",
       "35547  {'zhenskaya_odezhda_aksessuary_tip': 'Шарфы и ...   \n",
       "\n",
       "                                             image_links  \n",
       "0      http://cache3.youla.io/files/images/360_360/58...  \n",
       "1      http://cache3.youla.io/files/images/360_360/5b...  \n",
       "2      http://cache3.youla.io/files/images/360_360/59...  \n",
       "3      http://cache3.youla.io/files/images/360_360/57...  \n",
       "4      http://cache3.youla.io/files/images/360_360/5a...  \n",
       "...                                                  ...  \n",
       "35543  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35544  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35545  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35546  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35547  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "\n",
       "[35548 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset #dataset has already been pre-processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TfidfVectorizer object and fit it on out training set texts\n",
    "\n",
    "#vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features = 50000)\n",
    "#vectorizer.fit(train['text'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. convert texts to tf-idf vectors using .transform\n",
    "# 2. convert your labels into numpy arrays \n",
    "\n",
    "X_train = vectorizer.transform(train['text'])\n",
    "y_train = np.array(train['label'], int)\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "y_test = np.array(test['label'], int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the classifier::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LogisticRegression model object and fit the model\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865634892718959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (predictions == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1 = 'Блузка Темно-синяя'\n",
    "\n",
    "vec = vectorizer.transform([q_1])\n",
    "model.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_2 = 'Энергетики, вредно или нет?'\n",
    "\n",
    "vec = vectorizer.transform([q_2])\n",
    "model.predict(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we use the model LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990995427365459"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions_clf = clf.predict(X_test)\n",
    "accuracy_clf = (predictions_clf == y_test).mean()\n",
    "accuracy_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OMG, we'll take LinearSVC as our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll save the model into the file and going to load: \n",
    "\n",
    "with open('project14_clf.pkl', 'wb') as output:\n",
    "    pickle.dump(clf, output) #save\n",
    "\n",
    "with open('project14_clf.pkl', 'rb') as pkl_file:\n",
    "    regressor_from_file = pickle.load(pkl_file) #load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(question):\n",
    "    vec = vectorizer.transform([question])\n",
    "    predicted_answer = model.predict(vec)[0]\n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll check saving and loading correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('Блузка Темно-синяя')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('Энергетики, вредно или нет?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We implement the search for similar products in the content part of the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = pd.read_csv('ProductsDataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All product names will be rolled into a vector representation Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MorphAnalyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m morpher \u001b[38;5;241m=\u001b[39m \u001b[43mMorphAnalyzer\u001b[49m()\n\u001b[0;32m      4\u001b[0m sw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(get_stop_words(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mru\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      5\u001b[0m exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(string\u001b[38;5;241m.\u001b[39mpunctuation)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MorphAnalyzer' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "for line in product_data['title']:\n",
    "    spls = prepro_txt(line)\n",
    "    sentences.append(spls)\n",
    "    c += 1\n",
    "    if c > 500000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model word2vec \n",
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "model_wv = Word2Vec(sentences=sentences, vector_size=100, min_count=5, window=5)\n",
    "model_wv.save(\"w2v_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build an index on the titles of the documents. Using the library 'annoy'. We go through all the names, we believe that the supply vector is the sum word2vec words, that are included in it (of course, the average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_goods = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "index_map_goods = {}\n",
    "counter = 0\n",
    "\n",
    "for line in product_data['title']:\n",
    "    n_w2v = 0\n",
    "    spls = line.split(\"\\t\")\n",
    "    index_map_goods[counter] = spls[0]\n",
    "    question = prepro_txt(spls[0])\n",
    "    vector = np.zeros(100)\n",
    "    for word in question:\n",
    "        if word in model_wv.wv:\n",
    "            vector += model_wv.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    index_goods.add_item(counter, vector)\n",
    "            \n",
    "    counter += 1\n",
    "\n",
    "index_goods.build(10)\n",
    "index_goods.save('smth.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the search for the answer by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working normally\n",
    "def find_answer(question, model):\n",
    "    preprocessed_question = prepro_txt(question)\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    for word in preprocessed_question:\n",
    "        if word in model_wv.wv:\n",
    "            vector += model_wv.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    answer_index = index_goods.get_nns_by_vector(vector, 1)\n",
    "    return index_map_goods[answer_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Юбка детская'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка... ну такое себе\n",
    "find_answer('Юбка детская ORBY', model_wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We implement chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess the mail.ru answers from the file: add 1 answer to each question and write it to the file for the future. This will allow us to save time and resources during further text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-2f773e5bf4ec>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(fin):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bc82d085be4f41aba8f3fbbdb4f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = None\n",
    "written = False\n",
    "\n",
    "#Мы идем по всем записям, берем первую строку как вопрос\n",
    "# и после знака --- находим ответ\n",
    "with open(\"prepared_answers.txt\", \"w\") as fout:\n",
    "    with open(\"Otvety.txt\", \"r\") as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to preprocess the text in order to train word2vec and get embeddings. Removing punctuation marks and doing lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-5fb97a84af0d>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(fin):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05d5543ea90483fa88b06a2730a241f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"Otvety.txt\", \"r\") as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = prepro_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 500000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model word2vec on our questions\n",
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "model_chat = Word2Vec(sentences=sentences, vector_size=100, min_count=1, window=5)\n",
    "model_chat.save(\"w2v_model_chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add all the questions to the index. Using the library annoy. We go through all the answers, we believe that the sentence vector is the sum of the word2vecs of the words that are included in it (averaged, of course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-2392c23e0b69>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(f):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8c125d5c5a4e91b9cc140d6d126b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"prepared_answers.txt\", \"r\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_w2v = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = prepro_txt(spls[0])\n",
    "        vector = np.zeros(100)\n",
    "        for word in question:\n",
    "            if word in model_chat.wv:\n",
    "                vector += model_chat.wv[word]\n",
    "                n_w2v += 1\n",
    "        if n_w2v > 0:\n",
    "            vector = vector / n_w2v\n",
    "        index.add_item(counter, vector)\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "index.build(10)\n",
    "index.save('speaker.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it remains to implement a method that will receive a question as an input and find an answer to it! We preprocess the question, find the closest question, and select the answer to the closest question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer_chat(question):\n",
    "    preprocessed_question = prepro_txt(question)\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    for word in preprocessed_question:\n",
    "        if word in model_chat.wv:\n",
    "            vector += model_chat.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    answer_index = index.get_nns_by_vector(vector, 1)\n",
    "    return index_map[answer_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'у нас тепло и дождей не предвидеться до ноября. \\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "find_answer_chat('Как погодка?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a chat bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    \n",
    "    # Классифицируем\n",
    "    predicted_question = get_predictions(question)\n",
    "    \n",
    "    # Ищем ответ в таблице\n",
    "    if predicted_question == 0:\n",
    "        find_in_table = find_answer(question, model_wv)\n",
    "        for counter, item in enumerate(product_data.title):\n",
    "            if item == find_in_table:\n",
    "                answ_to_return = [product_data.product_id[counter], product_data.title[counter]]\n",
    "                break\n",
    "    \n",
    "    # Chatting\n",
    "    else:\n",
    "        answ_to_return = find_answer_chat(question)\n",
    "        \n",
    "    return answ_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5922cd12de885467545e72a2', 'Юбка для девочки.']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer('Юбка детская ORBY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'у нас тепло и дождей не предвидеться до ноября. \\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer('Как погодка?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(get_answer('Юбка детская ORBY').startswith('58e3cfe6132ca50e053f5f82'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not get_answer('Где ключи от танка').startswith('5')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
